{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81d3ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sri Balaji Muruganandam\n",
    "### AAAMLP Book - Evaluation Metrics(Abhishek Thagur Book)\n",
    "### Metrics - Classification & Regression\n",
    "### Notebook - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ccc82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nReferences\\n\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "References\n",
    "https://www.youtube.com/watch?v=2osIZ-dSPGE\n",
    "https://www.mage.ai/blog/definitive-guide-to-accuracy-precision-recall-for-product-developers\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b70e41b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc9e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### If there are equal number of positive and negative samples in binary classification we use\n",
    "### the metrics of - accuracy, precision, recall and F1\n",
    "\n",
    "# Function to calculate accuracy - MANUAL Method\n",
    "\n",
    "def accuracy(actual,predict):\n",
    "    ## Abhi's approch\n",
    "    ## Initialize a simple counter for correct predictions\n",
    "    count = 0\n",
    "    \n",
    "    for act,pred in zip(actual,predict):\n",
    "        if(act==pred):\n",
    "            count+=1\n",
    "        \n",
    "    return count/len(actual)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7978e71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate accuracy - Scikit Learn\n",
    "actual = [0,1,1,1,0,0,1,1]\n",
    "predict = [0,0,1,1,1,0,1,1]\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(actual,predict)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "867de12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1],\n",
       "       [1, 4]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Whenever the data is skewed 180 positives and 20 negatives - Don't use accuracy\n",
    "### Use precisions -  know TP,TN, FP,FN (Confusion Matrix)\n",
    "\n",
    "\"\"\"\n",
    "Functions to calculate - True positive, True Negative, False Positive, False Negative\n",
    "We are going to use sklearn inbuilt functions, We can also create our own functions manually\n",
    "\"\"\"\n",
    "\n",
    "## ACCURACY SCORE = (TP+TN)/(TP+TN+FP+FN) -- This is our usual accuracy metrics for classification\n",
    "\n",
    "\"\"\"\n",
    "Note: Abhi has manually all the code for TP,TN, FP,FN, Precision, accuracy, recall etc...\n",
    "Know the concepts well and use built-in functions from sklearn\n",
    "\"\"\"\n",
    "\n",
    "metrics.confusion_matrix(actual,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57290a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPRECISION = TP / (TP + FP)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Precision\n",
    "\n",
    "\"\"\"\n",
    "PRECISION = TP / (TP + FP)\n",
    "\"\"\"\n",
    "\n",
    "## We can say Precisoin is the probability/likelihood of the model to predict positive cases or negative cases\n",
    "## How well your model predicts a specific category\n",
    "## For multiclass There will be precision for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e61b5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor precisions, think of predictions as your base\\n\\nFor Recall, think of truth as your base\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IMPORTANT\n",
    "\"\"\"\n",
    "For precisions, think of predictions as your base\n",
    "\n",
    "For Recall, think of truth as your base\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5d3259d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRECALL = TP / (TP + FN)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Recall is from positive actual values how many are correctly identified\n",
    "\n",
    "\"\"\"\n",
    "RECALL = TP / (TP + FN)\n",
    "\"\"\"\n",
    "\n",
    "### How well the model identified the positive cases is recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cc58e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIf recall is high it provides less false negatives. If precison is high it provides less false positives\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### For a good model our precision and recall should be high\n",
    "\n",
    "\"\"\"\n",
    "When do we need high precision or high recall? \n",
    "Models need high recall when you need output-sensitive predictions. \n",
    "For example, predicting cancer or predicting terrorists needs a high recall, in other words, \n",
    "you need to cover false negatives as well.\n",
    "\"\"\"\n",
    "\n",
    "### F1 score is the overall health of the model\n",
    "\n",
    "\n",
    "### Tentative intution\n",
    "\"\"\"\n",
    "If recall is high it provides less false negatives. If precison is high it provides less false positives\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d4930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
